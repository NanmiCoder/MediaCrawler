"""
MediaCrawler API Server
æä¾›ç»Ÿä¸€çš„ REST API æ¥å£ï¼Œæ”¯æŒæŠ–éŸ³ã€å°çº¢ä¹¦ã€çŸ¥ä¹æ•°æ®é‡‡é›†
"""
import asyncio
import json
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Optional, List, Dict
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
import uvicorn

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

import config
from tools import utils

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="MediaCrawler API",
    description="ç»Ÿä¸€çš„ç¤¾äº¤åª’ä½“æ•°æ®é‡‡é›† API - æ”¯æŒæŠ–éŸ³ã€å°çº¢ä¹¦ã€çŸ¥ä¹",
    version="1.0.0"
)

# ==================== æ•°æ®æ¨¡å‹ ====================

class SearchRequest(BaseModel):
    """æœç´¢è¯·æ±‚"""
    platform: str = Field(..., description="å¹³å°ä»£ç : dy(æŠ–éŸ³), xhs(å°çº¢ä¹¦), zhihu(çŸ¥ä¹)")
    keyword: str = Field(..., description="æœç´¢å…³é”®è¯")
    max_count: int = Field(10, description="æœ€å¤§é‡‡é›†æ•°é‡", ge=1, le=50)
    enable_comments: bool = Field(True, description="æ˜¯å¦é‡‡é›†è¯„è®º")
    enable_media: bool = Field(False, description="æ˜¯å¦ä¸‹è½½åª’ä½“æ–‡ä»¶")

class SearchResponse(BaseModel):
    """æœç´¢å“åº”"""
    task_id: str = Field(..., description="ä»»åŠ¡ID")
    status: str = Field(..., description="ä»»åŠ¡çŠ¶æ€: pending, running, completed, failed")
    message: str = Field(..., description="æ¶ˆæ¯")
    data: Optional[Dict] = Field(None, description="ç»“æœæ•°æ®")

class TaskStatus(BaseModel):
    """ä»»åŠ¡çŠ¶æ€"""
    task_id: str
    status: str
    progress: Optional[str] = None
    result_file: Optional[str] = None
    error: Optional[str] = None

# ==================== å…¨å±€å˜é‡ ====================

# ä»»åŠ¡é˜Ÿåˆ—
tasks_status = {}

# ==================== è¾…åŠ©å‡½æ•° ====================

def validate_platform(platform: str) -> bool:
    """éªŒè¯å¹³å°ä»£ç """
    valid_platforms = ["dy", "xhs", "zhihu"]
    return platform in valid_platforms

async def run_crawler_task(task_id: str, platform: str, keyword: str,
                           max_count: int, enable_comments: bool, enable_media: bool):
    """è¿è¡Œçˆ¬è™«ä»»åŠ¡"""
    try:
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        tasks_status[task_id]["status"] = "running"
        tasks_status[task_id]["progress"] = "åˆå§‹åŒ–çˆ¬è™«..."

        # åŠ è½½å¹³å°Cookieé…ç½®
        try:
            from test_platform_cookies import get_cookie_for_platform
            platform_cookie = get_cookie_for_platform(platform)
            if platform_cookie:
                config.COOKIES = platform_cookie
                utils.logger.info(f"[API] Loaded cookie for platform: {platform}")
            else:
                utils.logger.warning(f"[API] No cookie configured for platform: {platform}")
        except ImportError:
            utils.logger.warning("[API] test_platform_cookies.py not found, using default cookie")

        # åŠ¨æ€ä¿®æ”¹é…ç½®
        config.PLATFORM = platform
        config.KEYWORDS = keyword
        config.CRAWLER_MAX_NOTES_COUNT = max_count
        config.ENABLE_GET_COMMENTS = enable_comments
        config.ENABLE_GET_MEIDAS = enable_media

        # æ ¹æ®å¹³å°å¯¼å…¥ç›¸åº”çš„çˆ¬è™«
        if platform == "dy":
            from media_platform.douyin import DouYinCrawler
            crawler = DouYinCrawler()
        elif platform == "xhs":
            from media_platform.xhs import XiaoHongShuCrawler
            crawler = XiaoHongShuCrawler()
        elif platform == "zhihu":
            from media_platform.zhihu import ZhihuCrawler
            crawler = ZhihuCrawler()
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å¹³å°: {platform}")

        tasks_status[task_id]["progress"] = "å¼€å§‹é‡‡é›†æ•°æ®..."

        # è¿è¡Œçˆ¬è™«
        await crawler.start()

        # æŸ¥æ‰¾ç”Ÿæˆçš„æ•°æ®æ–‡ä»¶
        data_dir = Path(f"data/{platform}/json")
        today = datetime.now().strftime("%Y-%m-%d")

        result_files = []
        if data_dir.exists():
            result_files = list(data_dir.glob(f"*{today}*.json"))

        if result_files:
            # è¯»å–æœ€æ–°çš„æ•°æ®æ–‡ä»¶
            latest_file = max(result_files, key=lambda p: p.stat().st_mtime)
            with open(latest_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            tasks_status[task_id]["status"] = "completed"
            tasks_status[task_id]["progress"] = "é‡‡é›†å®Œæˆ"
            tasks_status[task_id]["result_file"] = str(latest_file)
            tasks_status[task_id]["data"] = {
                "total": len(data) if isinstance(data, list) else 1,
                "keyword": keyword,
                "platform": platform,
                "file_path": str(latest_file),
                "items": data[:5] if isinstance(data, list) else data  # åªè¿”å›å‰5æ¡é¢„è§ˆ
            }
        else:
            tasks_status[task_id]["status"] = "completed"
            tasks_status[task_id]["progress"] = "é‡‡é›†å®Œæˆï¼Œä½†æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶"
            tasks_status[task_id]["data"] = {"message": "é‡‡é›†å®Œæˆï¼Œä½†æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶"}

    except Exception as e:
        tasks_status[task_id]["status"] = "failed"
        tasks_status[task_id]["error"] = str(e)
        utils.logger.error(f"[API] Task {task_id} failed: {e}")

# ==================== API è·¯ç”± ====================

@app.get("/")
async def root():
    """API é¦–é¡µ"""
    return {
        "name": "MediaCrawler API",
        "version": "1.0.0",
        "description": "ç»Ÿä¸€çš„ç¤¾äº¤åª’ä½“æ•°æ®é‡‡é›† API",
        "supported_platforms": {
            "dy": "æŠ–éŸ³",
            "xhs": "å°çº¢ä¹¦",
            "zhihu": "çŸ¥ä¹"
        },
        "endpoints": {
            "search": "POST /api/search - æœç´¢å¹¶é‡‡é›†æ•°æ®",
            "status": "GET /api/task/{task_id} - æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€",
            "platforms": "GET /api/platforms - è·å–æ”¯æŒçš„å¹³å°åˆ—è¡¨"
        },
        "docs": "/docs"
    }

@app.get("/api/platforms")
async def get_platforms():
    """è·å–æ”¯æŒçš„å¹³å°åˆ—è¡¨"""
    return {
        "platforms": [
            {
                "code": "dy",
                "name": "æŠ–éŸ³",
                "description": "çŸ­è§†é¢‘å¹³å°",
                "supported_types": ["æœç´¢", "ç”¨æˆ·", "è§†é¢‘è¯¦æƒ…"]
            },
            {
                "code": "xhs",
                "name": "å°çº¢ä¹¦",
                "description": "ç”Ÿæ´»æ–¹å¼åˆ†äº«å¹³å°",
                "supported_types": ["æœç´¢", "ç”¨æˆ·", "ç¬”è®°è¯¦æƒ…"]
            },
            {
                "code": "zhihu",
                "name": "çŸ¥ä¹",
                "description": "é—®ç­”ç¤¾åŒº",
                "supported_types": ["æœç´¢", "ç”¨æˆ·", "é—®é¢˜è¯¦æƒ…"]
            }
        ]
    }

@app.post("/api/search", response_model=SearchResponse)
async def search(request: SearchRequest, background_tasks: BackgroundTasks):
    """
    æœç´¢å¹¶é‡‡é›†æ•°æ®

    - **platform**: å¹³å°ä»£ç  (dy/xhs/zhihu)
    - **keyword**: æœç´¢å…³é”®è¯
    - **max_count**: æœ€å¤§é‡‡é›†æ•°é‡ (1-50)
    - **enable_comments**: æ˜¯å¦é‡‡é›†è¯„è®º
    - **enable_media**: æ˜¯å¦ä¸‹è½½åª’ä½“æ–‡ä»¶
    """
    # éªŒè¯å¹³å°
    if not validate_platform(request.platform):
        raise HTTPException(
            status_code=400,
            detail=f"ä¸æ”¯æŒçš„å¹³å°: {request.platform}ï¼Œæ”¯æŒçš„å¹³å°: dy, xhs, zhihu"
        )

    # ç”Ÿæˆä»»åŠ¡ID
    import random
    import string
    random_id = ''.join(random.choices(string.ascii_lowercase + string.digits, k=6))
    task_id = f"{request.platform}_{datetime.now().strftime('%Y%m%d%H%M%S')}_{random_id}"

    # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€
    tasks_status[task_id] = {
        "task_id": task_id,
        "status": "pending",
        "platform": request.platform,
        "keyword": request.keyword,
        "max_count": request.max_count,
        "created_at": datetime.now().isoformat(),
        "progress": None,
        "result_file": None,
        "error": None,
        "data": None
    }

    # åœ¨åå°è¿è¡Œçˆ¬è™«ä»»åŠ¡
    background_tasks.add_task(
        run_crawler_task,
        task_id,
        request.platform,
        request.keyword,
        request.max_count,
        request.enable_comments,
        request.enable_media
    )

    return SearchResponse(
        task_id=task_id,
        status="pending",
        message=f"ä»»åŠ¡å·²åˆ›å»ºï¼Œæ­£åœ¨åå°æ‰§è¡Œã€‚ä½¿ç”¨ GET /api/task/{task_id} æŸ¥è¯¢è¿›åº¦",
        data=None
    )

@app.get("/api/task/{task_id}", response_model=TaskStatus)
async def get_task_status(task_id: str):
    """
    æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€

    - **task_id**: ä»»åŠ¡ID
    """
    if task_id not in tasks_status:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    task = tasks_status[task_id]

    return TaskStatus(
        task_id=task["task_id"],
        status=task["status"],
        progress=task.get("progress"),
        result_file=task.get("result_file"),
        error=task.get("error")
    )

@app.get("/api/task/{task_id}/result")
async def get_task_result(task_id: str):
    """
    è·å–ä»»åŠ¡ç»“æœ

    - **task_id**: ä»»åŠ¡ID
    """
    if task_id not in tasks_status:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    task = tasks_status[task_id]

    if task["status"] != "completed":
        return JSONResponse(
            status_code=400,
            content={
                "error": "ä»»åŠ¡å°šæœªå®Œæˆ",
                "status": task["status"],
                "progress": task.get("progress")
            }
        )

    return {
        "task_id": task_id,
        "status": task["status"],
        "platform": task["platform"],
        "keyword": task["keyword"],
        "data": task.get("data"),
        "result_file": task.get("result_file")
    }

@app.get("/api/tasks")
async def list_tasks():
    """è·å–æ‰€æœ‰ä»»åŠ¡åˆ—è¡¨"""
    return {
        "total": len(tasks_status),
        "tasks": [
            {
                "task_id": task_id,
                "platform": task["platform"],
                "keyword": task["keyword"],
                "status": task["status"],
                "created_at": task["created_at"]
            }
            for task_id, task in tasks_status.items()
        ]
    }

@app.delete("/api/task/{task_id}")
async def delete_task(task_id: str):
    """åˆ é™¤ä»»åŠ¡è®°å½•"""
    if task_id not in tasks_status:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    del tasks_status[task_id]
    return {"message": f"ä»»åŠ¡ {task_id} å·²åˆ é™¤"}

# ==================== å¯åŠ¨æœåŠ¡ ====================

if __name__ == "__main__":
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    MediaCrawler API Server                     â•‘
â•‘                                                                â•‘
â•‘  ğŸš€ API æ–‡æ¡£: http://localhost:8080/docs                      â•‘
â•‘  ğŸ“Š æ”¯æŒå¹³å°: æŠ–éŸ³ | å°çº¢ä¹¦ | çŸ¥ä¹                            â•‘
â•‘  ğŸ”— API ç«¯ç‚¹: http://localhost:8080/api/search               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=8080,
        reload=True,
        log_level="info"
    )
